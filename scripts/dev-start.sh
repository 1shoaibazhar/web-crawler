#!/bin/bash

# Web Crawler Development Startup Script
echo "ğŸš€ Starting Web Crawler Development Environment..."

# Check if Docker is running
if ! docker info > /dev/null 2>&1; then
    echo "âŒ Docker is not running. Please start Docker first."
    exit 1
fi

# Start the services
echo "ğŸ“¦ Starting services with Docker Compose..."
docker-compose up -d mysql adminer

echo "â³ Waiting for MySQL to be ready..."
docker-compose exec mysql sh -c 'until mysqladmin ping -h localhost --silent; do echo "Waiting for MySQL..."; sleep 2; done'

echo "ğŸ”¨ Building and starting backend..."
docker-compose up -d backend

echo "âœ… Development environment is ready!"
echo ""
echo "ğŸŒ Services available at:"
echo "   â€¢ Backend API: http://localhost:8080"
echo "   â€¢ API Health: http://localhost:8080/health"
echo "   â€¢ Database Admin: http://localhost:8081 (adminer)"
echo "   â€¢ Database: localhost:3306"
echo ""
echo "ğŸ“Š Database credentials:"
echo "   â€¢ Server: mysql"
echo "   â€¢ Database: web_crawler"
echo "   â€¢ Username: crawler_user"
echo "   â€¢ Password: crawler_password"
echo ""
echo "ğŸ”§ Useful commands:"
echo "   â€¢ View logs: docker-compose logs -f backend"
echo "   â€¢ Stop services: docker-compose down"
echo "   â€¢ Rebuild backend: docker-compose build backend"
echo ""
echo "Happy coding! ğŸ‰" 